{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b7190d-ca26-4c63-a83f-851422ce2488",
   "metadata": {},
   "source": [
    "# GRU model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44ba32-5c58-4b99-983b-3ec26af16dac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93485f85-5771-4c8a-8be3-1187b53ca99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1446c46c-f4bb-4011-8ab7-9d849bd74a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Masking, GRU, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9139ebe0-d72a-4528-b210-6f4a921fc63d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../processed_data/features_1000sample_400min_600cutoff.csv\")\n",
    "y = pd.read_csv(\"../processed_data/target_1000sample_400min_600cutoff.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5fcd2d6-6b37-48a9-ac2b-d6e6f61bb10a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "codes = {p: i for i, p in enumerate(y[\"party\"].unique())}\n",
    "# y = y[\"party\"].map(codes)\n",
    "y = OneHotEncoder(sparse_output=False).fit_transform(y[\"party\"].values.reshape(-1, 1))\n",
    "X = X[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad267388-22a4-493e-b939-7892d6cd3eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000,), (7000, 7))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2cf940-35c4-4b2e-a938-1f9e1a22dfd5",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80120b28-4fe3-466c-9de6-57eb11c77525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865f4d5-da88-430d-b487-b011a71231e3",
   "metadata": {},
   "source": [
    "### Embed the training and test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5529d597-b059-41b9-82e9-27fc625ad27a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence_with_TF(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec:\n",
    "            embedded_sentence.append(word2vec[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence_with_TF(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfcbfff7-7a89-4891-9f34-09a995fa96e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "248f68ca-285f-4891-bcd1-c00f6ae8b896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_embed = embedding(word2vec_model, X_train)\n",
    "X_test_embed = embedding(word2vec_model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e2f88-9491-4643-9c15-74791472bc7c",
   "metadata": {},
   "source": [
    "### Pad sequences to ensure uniform input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "980a9a10-ffc0-4022-9165-83878ff4ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 600  # Maximum sequence length\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f953a36-7196-4228-befa-f433f61fd1f4",
   "metadata": {},
   "source": [
    "### Tokenize the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e14ba8-0d87-4b43-95ae-01c60f25fda8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer(num_words=10000)  # Limit vocabulary size\n",
    "# tokenizer.fit_on_texts(X_train)\n",
    "# X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "# X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb3dbfc-a723-4e60-bf61-564f2b46fbe2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b275137-b08c-4930-a237-cb32e6db3084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Convert words to Word2Vec embeddings\n",
    "# word_index = tokenizer.word_index\n",
    "# embedding_matrix = np.zeros((len(word_index) + 1, 300))  # Assuming Word2Vec vectors are 300-dimensional\n",
    "\n",
    "# for word, i in word_index.items():\n",
    "#     if word in word2vec_model:\n",
    "#         embedding_matrix[i] = word2vec_model[word]\n",
    "\n",
    "# # Define the model\n",
    "# embedding_layer = tf.keras.layers.Embedding(len(word_index) + 1,\n",
    "#                                             300,  # Assuming Word2Vec vectors are 300-dimensional\n",
    "#                                             weights=[embedding_matrix],\n",
    "#                                             input_length=maxlen,\n",
    "#                                             trainable=False)  # Freeze the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "22680562-6fc4-4925-9843-e78226998b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Masking())\n",
    "model.add(GRU(200, activation=\"tanh\", dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(GRU(100, activation=\"tanh\", dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dense(7, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "es = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a5f36f46-54fc-42cb-8dba-ede2ef6f70bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "140/140 [==============================] - 148s 1s/step - loss: 1.9470 - accuracy: 0.1525 - val_loss: 1.9484 - val_accuracy: 0.1455\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 147s 1s/step - loss: 1.9477 - accuracy: 0.1415 - val_loss: 1.9470 - val_accuracy: 0.1500\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 149s 1s/step - loss: 1.9465 - accuracy: 0.1509 - val_loss: 1.9480 - val_accuracy: 0.1420\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 147s 1s/step - loss: 1.9442 - accuracy: 0.1556 - val_loss: 1.9471 - val_accuracy: 0.1420\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 148s 1s/step - loss: 1.9456 - accuracy: 0.1513 - val_loss: 1.9486 - val_accuracy: 0.1437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f411f147220>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(np.array(X_train_pad), np.array(y_train), epochs=10, batch_size=32, \n",
    "          validation_split=0.2, callbacks=[es], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d0efe-d3fe-4da3-8f8b-8849ece830ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15d89e-06b8-458e-b470-ffc5442b3f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
